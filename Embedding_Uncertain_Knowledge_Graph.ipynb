{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Embedding_Uncertain_Knowledge_Graph.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMcLjf19aAuyd/0opPY9Sqp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/odean111/KnowledgeGraph/blob/main/Embedding_Uncertain_Knowledge_Graph.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTeajDtRZkD6"
      },
      "source": [
        "Import TSV File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaTUel7BYv8g"
      },
      "source": [
        "## Extract TSV and put into a dataframe\n",
        "\n",
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "tsv_file = open(\"Knowledge Graph - Known Relationship.tsv\")\n",
        "kg = csv.reader(tsv_file, delimiter=\"\\t\")\n",
        "cols = ['ent_1', 'ent_2', 'rel', 'conf']\n",
        "\n",
        "ls_kg = []\n",
        "for row in kg:\n",
        "  ls_kg.append(row)\n",
        "\n",
        "df_kg = pd.DataFrame(data=ls_kg, columns=cols)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGWoNoU6eqW_"
      },
      "source": [
        "Create Set of Ground Truths - based on AND transivity\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2Z4ycmcuoHc"
      },
      "source": [
        "# import required packages\n",
        "import itertools\n",
        "\n",
        "\n",
        "# return a list of the nodes\n",
        "def unique_ent(df_input):\n",
        "  unq_ent_1 = df_input.ent_1.unique()\n",
        "  unq_ent_2 = df_input.ent_2.unique()\n",
        "  unq_ent = np.unique(np.concatenate((unq_ent_1, unq_ent_2)))\n",
        "  return unq_ent\n",
        "\n",
        "\n",
        "# Create a dataframe of all, return a dataframe \n",
        "def return_near_nodes(input_node, df_input):\n",
        "  ent_1_df = df_input.loc[df_input['ent_1'] == input_node]\n",
        "  ent_2_df = df_input.loc[df_input['ent_2'] == input_node]\n",
        "  df_rel = pd.concat([ent_2_df, ent_1_df])\n",
        "  df_near_ents = unique_ent(df_rel)\n",
        "  np_near_nodes = np.delete(df_near_ents, np.where(df_near_ents == input_node))\n",
        "  # return df_rel, np_near_ents\n",
        "  return np_near_nodes\n",
        "\n",
        "\n",
        "# Return list of unseen relationships\n",
        "def return_unseen_relationships(np_near_ents, df_input):\n",
        "  unseen_relationships = []\n",
        "  combinations = itertools.combinations(np_near_ents, 2)\n",
        "  for relationships in combinations:\n",
        "    if len(df_input.loc[df_input['ent_1'] == relationships[0]].loc[df_input['ent_2'] == relationships[1]]) > 0:\n",
        "      pass\n",
        "    elif len(df_input.loc[df_input['ent_1'] == relationships[1]].loc[df_input['ent_2'] == relationships[0]]) > 0:\n",
        "      pass\n",
        "    else:\n",
        "      unseen_relationships.append(relationships)\n",
        "  return unseen_relationships\n",
        "    \n",
        "    \n",
        "# Calculate truth value via an intermediatary node\n",
        "def truth_val_calc(unseen_relationships, df_input, central_node):\n",
        "  \n",
        "  ls_rel_tvals = []\n",
        "  for ele in unseen_relationships:\n",
        "    ent_1 = ele[0]\n",
        "    ent_2 = ele[1]\n",
        "    if len(df_input.loc[df_input['ent_1'] == ent_1].loc[df_input['ent_2'] == central_node]['conf'].tolist()) > 0:\n",
        "      tval_1 = df_input.loc[df_input['ent_1'] == ent_1].loc[df_input['ent_2'] == central_node]['conf'].tolist()[0]\n",
        "    elif len(df_input.loc[df_input['ent_2'] == ent_1].loc[df_input['ent_1'] == central_node]['conf'].tolist()) > 0:\n",
        "      tval_1 = df_input.loc[df_input['ent_2'] == ent_1].loc[df_input['ent_1'] == central_node]['conf'].tolist()[0]\n",
        "\n",
        "    if len(df_input.loc[df_input['ent_1'] == ent_2].loc[df_input['ent_2'] == central_node]['conf'].tolist()) > 0:\n",
        "      tval_2 = df_input.loc[df_input['ent_1'] == ent_2].loc[df_input['ent_2'] == central_node]['conf'].tolist()[0]\n",
        "    elif len(df_input.loc[df_input['ent_2'] == ent_2].loc[df_input['ent_1'] == central_node]['conf'].tolist()) > 0:\n",
        "      tval_2 = df_input.loc[df_input['ent_2'] == ent_2].loc[df_input['ent_1'] == central_node]['conf'].tolist()[0]\n",
        "    relationship_vals = [ent_1, ent_2, float(tval_1) + float(tval_2)]\n",
        "    ls_rel_tvals.append(relationship_vals)\n",
        "  \n",
        "  return ls_rel_tvals\n",
        "\n",
        "\n",
        "# Return a list of all unseen relationships and their minimum truth values (ground truths)\n",
        "def return_ground_truths(input_df):\n",
        "  unique_nodes = unique_ent(input_df).tolist()\n",
        "  unseen_relationships_ls = []\n",
        "  for node in unique_nodes:\n",
        "    near_nodes = return_near_nodes(node, input_df)\n",
        "    unseen_relationships = return_unseen_relationships(near_nodes, input_df)\n",
        "    unseen_relationships_ls.extend(truth_val_calc(unseen_relationships, input_df, node))\n",
        "  return unseen_relationships_ls"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUn9fOSw7lKe"
      },
      "source": [
        "ls_ground_truths = return_ground_truths(df_kg)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I70qv8qu-TtA"
      },
      "source": [
        "ls_kg_wo_rels = []\n",
        "for ele in ls_kg:\n",
        "  confid = ele[3:][0]\n",
        "  confid = float(confid)\n",
        "  new_ele = ele[0:2]\n",
        "  new_ele.append(confid)\n",
        "  ls_kg_wo_rels.append(new_ele)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Elu89GGA15s",
        "outputId": "7d70de76-c49e-4191-c37f-06a618ea881f"
      },
      "source": [
        "print(ls_ground_truths)\n",
        "print(ls_kg_wo_rels)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['Phoebe', 'Ross', 1.83], ['Joey', 'Monica', 1.76], ['Joey', 'Rachel', 1.87], ['Monica', 'Ross', 1.35], ['Phoebe', 'Ross', 1.4], ['Chandler', 'Joey', 1.73], ['Chandler', 'Rachel', 1.37], ['Joey', 'Rachel', 1.3599999999999999]]\n",
            "[['Rachel', 'Monica', 0.85], ['Rachel', 'Phoebe', 0.9], ['Rachel', 'Ross', 0.5], ['Ross', 'Chandler', 0.87], ['Ross', 'Joey', 0.86], ['Joey', 'Phoebe', 0.97], ['Monica', 'Phoebe', 0.79]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYOI5-jEBHGL"
      },
      "source": [
        "Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vgzwvs2KBJEZ"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import autograd"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klP4ZlnbEuVx"
      },
      "source": [
        "class Network(nn.Module):\n",
        "  def __init__ (self, input_dims, output_dims):\n",
        "    super(Network, self).__init__()\n",
        "    self.fc1 = nn.Linear(in_features=input_dims, out_features=output_dims)\n",
        "\n",
        "  def forward(self, t):\n",
        "    # (1) input layer\n",
        "    t = t\n",
        "\n",
        "    # (2) hidden conv layer\n",
        "    t = self.fc1(t)\n",
        "    t = F.relu(t)\n",
        "\n",
        "    # (3) return values\n",
        "    return t"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1kq-uMSFvS_",
        "outputId": "70de47d5-0585-4d8a-d1f7-d53c94b28fb0"
      },
      "source": [
        "network = Network(7, 3)\n",
        "\n",
        "torch_1 = torch.tensor([1, 0, 0, 0, 0, 0, 0], dtype=torch.float32)\n",
        "torch_2 = torch.tensor([0, 1, 0, 0, 0, 0, 0], dtype=torch.float32)\n",
        "torch_3 = torch.tensor([0, 0, 1, 0, 0, 0, 0], dtype=torch.float32)\n",
        "output_1 = network(torch_1)\n",
        "output_2 = network(torch_2)\n",
        "output_3 = network(torch_3)\n",
        "\n",
        "hadamard_prod = output_1 * output_2\n",
        "output = torch.dot(hadamard_prod, output_3)\n",
        "\n",
        "print(output)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.0351, grad_fn=<DotBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}